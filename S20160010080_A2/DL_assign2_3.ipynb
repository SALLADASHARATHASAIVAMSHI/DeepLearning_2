{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_assign2_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NFRw6UFW44U4",
        "colab_type": "code",
        "outputId": "1ce28c1b-77fb-404a-fd8d-87dd77bb44b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pK5KzUru5Bp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UdmP_1l85G7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 32\n",
        "learn_rate = 0.001\n",
        "image_shape = (3, 28, 28)\n",
        "interval = 100\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "latentFeaturesShape = 3*28*28\n",
        "os.makedirs(\"3rd_question\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbaQOIND5MuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28*3, 64),\n",
        "            nn.ReLU(True), \n",
        "            nn.Linear(64, 12),\n",
        "            nn.ReLU(True), \n",
        "            nn.Linear(12, 3))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(True), \n",
        "            nn.Linear(64, 28*28*3), \n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wAk2DU4-5wVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(image_shape)), 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        checkValidity = self.model(img_flat)\n",
        "\n",
        "        return checkValidity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fr2Wm5358x7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GAN_loss = torch.nn.BCELoss()\n",
        "mse_loss = torch.nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jHcgwrwvqhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSEXDIHP6BzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GeneratorOptimizer = torch.optim.Adam(generator.parameters(), lr=learn_rate, betas=(beta1, beta2))\n",
        "DiscriminatorOptimizer = torch.optim.Adam(discriminator.parameters(), lr=learn_rate, betas=(beta1, beta2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycMdFpXW7ITc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tensor = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJpITp8s7KfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_dir = 'drive/My Drive/faces94'\n",
        "files = glob(f\"{root_dir}/**/**/*.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stlvbja87MaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vam = {\n",
        "    \"female\": 0,\n",
        "    \"male\":1,\n",
        "    \"malestaff\": 2 \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bs3AmjG7Q8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transformLoader = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((28, 28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gf3bfZnP7TqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "All_Images = torch.stack([transformLoader(Image.open(x)) for x in files])\n",
        "All_Labels = torch.tensor([vam[x.split('/')[-3]] for x in files])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DSKvVGDu7YXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getDataloaders(All_Images,All_Labels):\n",
        "  train_data, test_data = train_test_split(range(len(All_Images)), test_size=0.2, random_state=102)\n",
        "  train_images = All_Images[train_data]\n",
        "  train_label = All_Labels[train_data]\n",
        "\n",
        "  test_images = All_Images[test_data]\n",
        "  test_label = All_Labels[test_data]\n",
        "\n",
        "  train_data = TensorDataset(train_images, train_label)\n",
        "  test_data = TensorDataset(test_images, test_label)\n",
        "\n",
        "  train_samp = RandomSampler(train_data)\n",
        "  test_samp = SequentialSampler(test_data)\n",
        "\n",
        "  trainDataLoader = DataLoader(train_data, sampler=train_samp, batch_size=32)\n",
        "  testDataLoader = DataLoader(test_data, sampler=test_samp, batch_size=32)  \n",
        "  return trainDataLoader,testDataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZk67xH67cJU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainDataLoader,testDataLoader = getDataloaders(All_Images,All_Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xWg3e3a7h20",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_model(epochs,trainDataLoader,testDataLoader,latentFeaturesShape,GeneratorOptimizer,DiscriminatorOptimizer):\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images,_) in enumerate(trainDataLoader):\n",
        "          valid = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "          fake = Variable(Tensor(images.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "          trueImages = Variable(images.type(Tensor))\n",
        "          GeneratorOptimizer.zero_grad()\n",
        "          z = Variable(Tensor(np.random.normal(0, 1, (images.shape[0], latentFeaturesShape))))\n",
        "          generatedImages = generator(z)\n",
        "          GeneratorImagesLoss = GAN_loss(discriminator(generatedImages), valid)\n",
        "          GeneratorImagesLoss.backward()\n",
        "          GeneratorOptimizer.step()\n",
        "          DiscriminatorOptimizer.zero_grad()\n",
        "          real_loss = GAN_loss(discriminator(trueImages), valid)\n",
        "          fake_loss = GAN_loss(discriminator(generatedImages.detach()), fake)\n",
        "          DiscriminatorLoss = (real_loss + fake_loss) / 2\n",
        "          DiscriminatorLoss.backward()\n",
        "          DiscriminatorOptimizer.step()\n",
        "\n",
        "          print(\n",
        "              \"{ Epoch --> %d of %d}  { Batch --> %d of %d }  { Generator using AutoEncoder Loss --> %f }  { Discriminator Loss --> %f }\"\n",
        "              % (epoch+1, epochs, i+1, len(trainDataLoader),GeneratorImagesLoss.item(),DiscriminatorLoss.item())\n",
        "          )\n",
        "\n",
        "          FinishedBatches = epoch * len(trainDataLoader) + i\n",
        "          if FinishedBatches % interval == 0:\n",
        "              save_image(generatedImages.data[:25], \"3rd_question/%d.png\" % FinishedBatches, nrow=5, normalize=True)  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sP0fd6mCAK2",
        "colab_type": "code",
        "outputId": "7d31333f-46bb-46b7-de21-c96bfc013b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1305
        }
      },
      "cell_type": "code",
      "source": [
        "run_model(epochs,trainDataLoader,testDataLoader,latentFeaturesShape,GeneratorOptimizer,DiscriminatorOptimizer)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{ Epoch --> 1 of 1}  { Batch --> 1 of 77 }  { Generator using AutoEncoder Loss --> 0.719847 }  { Discriminator Loss --> 0.694726 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 2 of 77 }  { Generator using AutoEncoder Loss --> 0.782165 }  { Discriminator Loss --> 0.506493 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 3 of 77 }  { Generator using AutoEncoder Loss --> 0.886941 }  { Discriminator Loss --> 0.373206 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 4 of 77 }  { Generator using AutoEncoder Loss --> 1.041904 }  { Discriminator Loss --> 0.277516 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 5 of 77 }  { Generator using AutoEncoder Loss --> 1.258887 }  { Discriminator Loss --> 0.211822 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 6 of 77 }  { Generator using AutoEncoder Loss --> 1.535622 }  { Discriminator Loss --> 0.161699 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 7 of 77 }  { Generator using AutoEncoder Loss --> 1.856163 }  { Discriminator Loss --> 0.092084 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 8 of 77 }  { Generator using AutoEncoder Loss --> 2.151625 }  { Discriminator Loss --> 0.074634 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 9 of 77 }  { Generator using AutoEncoder Loss --> 2.387208 }  { Discriminator Loss --> 0.060666 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 10 of 77 }  { Generator using AutoEncoder Loss --> 2.521980 }  { Discriminator Loss --> 0.057163 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 11 of 77 }  { Generator using AutoEncoder Loss --> 2.546492 }  { Discriminator Loss --> 0.049892 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 12 of 77 }  { Generator using AutoEncoder Loss --> 2.469289 }  { Discriminator Loss --> 0.053048 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 13 of 77 }  { Generator using AutoEncoder Loss --> 2.320669 }  { Discriminator Loss --> 0.056472 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 14 of 77 }  { Generator using AutoEncoder Loss --> 2.111980 }  { Discriminator Loss --> 0.073661 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 15 of 77 }  { Generator using AutoEncoder Loss --> 1.881091 }  { Discriminator Loss --> 0.088721 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 16 of 77 }  { Generator using AutoEncoder Loss --> 1.698003 }  { Discriminator Loss --> 0.146562 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 17 of 77 }  { Generator using AutoEncoder Loss --> 1.448578 }  { Discriminator Loss --> 0.144860 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 18 of 77 }  { Generator using AutoEncoder Loss --> 1.671484 }  { Discriminator Loss --> 0.166302 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 19 of 77 }  { Generator using AutoEncoder Loss --> 0.918299 }  { Discriminator Loss --> 0.268697 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 20 of 77 }  { Generator using AutoEncoder Loss --> 1.341251 }  { Discriminator Loss --> 0.208881 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 21 of 77 }  { Generator using AutoEncoder Loss --> 1.622336 }  { Discriminator Loss --> 0.145891 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 22 of 77 }  { Generator using AutoEncoder Loss --> 1.732603 }  { Discriminator Loss --> 0.100998 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 23 of 77 }  { Generator using AutoEncoder Loss --> 1.649797 }  { Discriminator Loss --> 0.115196 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 24 of 77 }  { Generator using AutoEncoder Loss --> 1.531705 }  { Discriminator Loss --> 0.141859 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 25 of 77 }  { Generator using AutoEncoder Loss --> 1.855323 }  { Discriminator Loss --> 0.092227 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 26 of 77 }  { Generator using AutoEncoder Loss --> 1.786456 }  { Discriminator Loss --> 0.107487 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 27 of 77 }  { Generator using AutoEncoder Loss --> 1.423137 }  { Discriminator Loss --> 0.189992 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 28 of 77 }  { Generator using AutoEncoder Loss --> 1.184919 }  { Discriminator Loss --> 0.289088 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 29 of 77 }  { Generator using AutoEncoder Loss --> 0.788523 }  { Discriminator Loss --> 0.336646 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 30 of 77 }  { Generator using AutoEncoder Loss --> 1.779065 }  { Discriminator Loss --> 0.259460 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 31 of 77 }  { Generator using AutoEncoder Loss --> 0.874099 }  { Discriminator Loss --> 0.364531 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 32 of 77 }  { Generator using AutoEncoder Loss --> 0.799177 }  { Discriminator Loss --> 0.363522 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 33 of 77 }  { Generator using AutoEncoder Loss --> 1.093804 }  { Discriminator Loss --> 0.352292 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 34 of 77 }  { Generator using AutoEncoder Loss --> 0.739100 }  { Discriminator Loss --> 0.385142 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 35 of 77 }  { Generator using AutoEncoder Loss --> 0.955367 }  { Discriminator Loss --> 0.274912 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 36 of 77 }  { Generator using AutoEncoder Loss --> 0.901269 }  { Discriminator Loss --> 0.291299 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 37 of 77 }  { Generator using AutoEncoder Loss --> 1.110530 }  { Discriminator Loss --> 0.301773 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 38 of 77 }  { Generator using AutoEncoder Loss --> 0.998489 }  { Discriminator Loss --> 0.252810 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 39 of 77 }  { Generator using AutoEncoder Loss --> 0.990846 }  { Discriminator Loss --> 0.257001 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 40 of 77 }  { Generator using AutoEncoder Loss --> 1.484597 }  { Discriminator Loss --> 0.154783 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 41 of 77 }  { Generator using AutoEncoder Loss --> 1.461619 }  { Discriminator Loss --> 0.160323 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 42 of 77 }  { Generator using AutoEncoder Loss --> 1.595582 }  { Discriminator Loss --> 0.135021 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 43 of 77 }  { Generator using AutoEncoder Loss --> 1.637320 }  { Discriminator Loss --> 0.165134 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 44 of 77 }  { Generator using AutoEncoder Loss --> 1.524898 }  { Discriminator Loss --> 0.204278 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 45 of 77 }  { Generator using AutoEncoder Loss --> 2.446255 }  { Discriminator Loss --> 0.078562 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 46 of 77 }  { Generator using AutoEncoder Loss --> 2.581034 }  { Discriminator Loss --> 0.074915 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 47 of 77 }  { Generator using AutoEncoder Loss --> 2.833865 }  { Discriminator Loss --> 0.162335 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 48 of 77 }  { Generator using AutoEncoder Loss --> 2.174168 }  { Discriminator Loss --> 0.193717 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 49 of 77 }  { Generator using AutoEncoder Loss --> 5.578363 }  { Discriminator Loss --> 0.031300 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 50 of 77 }  { Generator using AutoEncoder Loss --> 5.979515 }  { Discriminator Loss --> 0.014920 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 51 of 77 }  { Generator using AutoEncoder Loss --> 4.311101 }  { Discriminator Loss --> 0.034807 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 52 of 77 }  { Generator using AutoEncoder Loss --> 3.515216 }  { Discriminator Loss --> 0.061074 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 53 of 77 }  { Generator using AutoEncoder Loss --> 5.389057 }  { Discriminator Loss --> 0.010379 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 54 of 77 }  { Generator using AutoEncoder Loss --> 5.195189 }  { Discriminator Loss --> 0.062194 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 55 of 77 }  { Generator using AutoEncoder Loss --> 6.440814 }  { Discriminator Loss --> 0.061397 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 56 of 77 }  { Generator using AutoEncoder Loss --> 3.818045 }  { Discriminator Loss --> 0.131578 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 57 of 77 }  { Generator using AutoEncoder Loss --> 8.566667 }  { Discriminator Loss --> 0.013451 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 58 of 77 }  { Generator using AutoEncoder Loss --> 8.184622 }  { Discriminator Loss --> 0.013599 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 59 of 77 }  { Generator using AutoEncoder Loss --> 5.349695 }  { Discriminator Loss --> 0.003602 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 60 of 77 }  { Generator using AutoEncoder Loss --> 1.586075 }  { Discriminator Loss --> 0.433629 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 61 of 77 }  { Generator using AutoEncoder Loss --> 12.394173 }  { Discriminator Loss --> 0.031776 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 62 of 77 }  { Generator using AutoEncoder Loss --> 15.901011 }  { Discriminator Loss --> 0.086571 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 63 of 77 }  { Generator using AutoEncoder Loss --> 12.124878 }  { Discriminator Loss --> 0.005744 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 64 of 77 }  { Generator using AutoEncoder Loss --> 7.639388 }  { Discriminator Loss --> 0.011785 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 65 of 77 }  { Generator using AutoEncoder Loss --> 4.593982 }  { Discriminator Loss --> 0.066428 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 66 of 77 }  { Generator using AutoEncoder Loss --> 1.797027 }  { Discriminator Loss --> 0.244156 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 67 of 77 }  { Generator using AutoEncoder Loss --> 2.727922 }  { Discriminator Loss --> 0.173446 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 68 of 77 }  { Generator using AutoEncoder Loss --> 4.969979 }  { Discriminator Loss --> 0.098692 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 69 of 77 }  { Generator using AutoEncoder Loss --> 4.396227 }  { Discriminator Loss --> 0.146153 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 70 of 77 }  { Generator using AutoEncoder Loss --> 5.121108 }  { Discriminator Loss --> 0.120964 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 71 of 77 }  { Generator using AutoEncoder Loss --> 4.289014 }  { Discriminator Loss --> 0.154997 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 72 of 77 }  { Generator using AutoEncoder Loss --> 5.256840 }  { Discriminator Loss --> 0.173976 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 73 of 77 }  { Generator using AutoEncoder Loss --> 5.202992 }  { Discriminator Loss --> 0.180700 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 74 of 77 }  { Generator using AutoEncoder Loss --> 2.657109 }  { Discriminator Loss --> 0.139185 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 75 of 77 }  { Generator using AutoEncoder Loss --> 2.910959 }  { Discriminator Loss --> 0.108165 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 76 of 77 }  { Generator using AutoEncoder Loss --> 3.649167 }  { Discriminator Loss --> 0.174633 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 77 of 77 }  { Generator using AutoEncoder Loss --> 2.936917 }  { Discriminator Loss --> 0.091919 }\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXR0xmN_CC_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}