{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_assign2_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K22rMtzbuLOX",
        "colab_type": "code",
        "outputId": "827e6dbc-45cc-4749-ae7e-439f6554e44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JU3ETruTY43d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfPhjoraZUyN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 32\n",
        "learn_rate = 0.001\n",
        "image_shape = (3, 200, 180)\n",
        "interval = 100\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "latentFeaturesShape = 200\n",
        "os.makedirs(\"1st_question\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1lTrMTaZhjM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_features, out_features, normalize=True):\n",
        "            layers = [nn.Linear(in_features, out_features)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_features, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latentFeaturesShape, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(image_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.avgpool =  nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *image_shape)\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnTSjCM-Zl69",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(image_shape)), 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        checkValidity = self.model(img_flat)\n",
        "\n",
        "        return checkValidity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDlC_um_Zpx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GAN_loss = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iwCKE-oZsl9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5n-AAQnhZvOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GeneratorOptimizer = torch.optim.Adam(generator.parameters(), lr=learn_rate, betas=(beta1, beta2))\n",
        "DiscriminatorOptimizer = torch.optim.Adam(discriminator.parameters(), lr=learn_rate, betas=(beta1, beta2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtQPDB4pZy-0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tensor = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvkkEyOfZ17s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_dir = 'drive/My Drive/faces94'\n",
        "files = glob(f\"{root_dir}/**/**/*.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSHtZBMwZ4YO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vam = {\n",
        "    \"female\": 0,\n",
        "    \"male\":1,\n",
        "    \"malestaff\": 2 \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrysitWQZ_JN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transformLoader = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-N62-V-NaCZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "All_Images = torch.stack([transformLoader(Image.open(x)) for x in files])\n",
        "All_Labels = torch.tensor([vam[x.split('/')[-3]] for x in files])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWJ-p_ntaO9t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getDataloaders(All_Images,All_Labels):\n",
        "  train_data, test_data = train_test_split(range(len(All_Images)), test_size=0.2, random_state=102)\n",
        "  train_images = All_Images[train_data]\n",
        "  train_label = All_Labels[train_data]\n",
        "  test_images = All_Images[test_data]\n",
        "  test_label = All_Labels[test_data]\n",
        "  train_data = TensorDataset(train_images, train_label)\n",
        "  test_data = TensorDataset(test_images, test_label)\n",
        "  sampleTrain = RandomSampler(train_data)\n",
        "  sampleTest = SequentialSampler(test_data)\n",
        "  trainDataLoader = DataLoader(train_data, sampler=sampleTrain, batch_size=32)\n",
        "  testDataLoader = DataLoader(test_data, sampler=sampleTest, batch_size=32)\n",
        "  \n",
        "  return trainDataLoader,testDataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8XCHNuUr5ck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainDataLoader,testDataLoader=getDataloaders(All_Images,All_Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BK1UNyb_aT99",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_model(epochs,trainDataLoader,testDataLoader,latentFeaturesShape,GeneratorOptimizer,DiscriminatorOptimizer):\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images,_) in enumerate(trainDataLoader):\n",
        "          valid = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "          fake = Variable(Tensor(images.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "          trueImages = Variable(images.type(Tensor))\n",
        "          GeneratorOptimizer.zero_grad()\n",
        "          z = Variable(Tensor(np.random.normal(0, 1, (images.shape[0], latentFeaturesShape))))\n",
        "          generatedImages = generator(z)\n",
        "          GeneratorImagesLoss = GAN_loss(discriminator(generatedImages), valid)\n",
        "          GeneratorImagesLoss.backward()\n",
        "          GeneratorOptimizer.step()\n",
        "          DiscriminatorOptimizer.zero_grad()\n",
        "          real_loss = GAN_loss(discriminator(trueImages), valid)\n",
        "          fake_loss = GAN_loss(discriminator(generatedImages.detach()), fake)\n",
        "          DiscriminatorLoss = (real_loss + fake_loss) / 2\n",
        "          DiscriminatorLoss.backward()\n",
        "          DiscriminatorOptimizer.step()\n",
        "\n",
        "          print(\n",
        "              \"{ Epoch --> %d of %d}  { Batch --> %d of %d }  { Generator Loss --> %f }  { Discriminator Loss --> %f }\"\n",
        "              % (epoch+1, epochs, i+1, len(trainDataLoader),GeneratorImagesLoss.item(),DiscriminatorLoss.item())\n",
        "          )\n",
        "\n",
        "          FinishedBatches = epoch * len(trainDataLoader) + i\n",
        "          if FinishedBatches % interval == 0:\n",
        "              save_image(generatedImages.data[:25], \"1st_question/%d.png\" % FinishedBatches, nrow=5, normalize=True)  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWgrVNAeCpsr",
        "colab_type": "code",
        "outputId": "5ea72d1e-cfb6-44bf-8502-e973608ecee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1305
        }
      },
      "cell_type": "code",
      "source": [
        "run_model(epochs,trainDataLoader,testDataLoader,latentFeaturesShape,GeneratorOptimizer,DiscriminatorOptimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{ Epoch --> 1 of 1}  { Batch --> 1 of 77 }  { Generator Loss --> 0.681613 }  { Discriminator Loss --> 0.696671 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 2 of 77 }  { Generator Loss --> 0.738853 }  { Discriminator Loss --> 0.324720 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 3 of 77 }  { Generator Loss --> 0.666741 }  { Discriminator Loss --> 0.361286 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 4 of 77 }  { Generator Loss --> 0.732876 }  { Discriminator Loss --> 0.332332 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 5 of 77 }  { Generator Loss --> 1.037325 }  { Discriminator Loss --> 0.229643 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 6 of 77 }  { Generator Loss --> 2.544907 }  { Discriminator Loss --> 0.041560 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 7 of 77 }  { Generator Loss --> 3.707690 }  { Discriminator Loss --> 15.920053 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 8 of 77 }  { Generator Loss --> 0.000183 }  { Discriminator Loss --> 4.432014 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 9 of 77 }  { Generator Loss --> 0.000163 }  { Discriminator Loss --> 4.514224 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 10 of 77 }  { Generator Loss --> 0.006162 }  { Discriminator Loss --> 2.594599 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 11 of 77 }  { Generator Loss --> 0.672900 }  { Discriminator Loss --> 0.906133 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 12 of 77 }  { Generator Loss --> 0.679775 }  { Discriminator Loss --> 0.353581 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 13 of 77 }  { Generator Loss --> 2.216370 }  { Discriminator Loss --> 0.109950 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 14 of 77 }  { Generator Loss --> 2.050562 }  { Discriminator Loss --> 0.072689 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 15 of 77 }  { Generator Loss --> 1.565283 }  { Discriminator Loss --> 0.125162 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 16 of 77 }  { Generator Loss --> 1.041602 }  { Discriminator Loss --> 0.275189 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 17 of 77 }  { Generator Loss --> 0.209829 }  { Discriminator Loss --> 0.832522 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 18 of 77 }  { Generator Loss --> 0.341854 }  { Discriminator Loss --> 0.730205 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 19 of 77 }  { Generator Loss --> 0.124045 }  { Discriminator Loss --> 1.074971 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 20 of 77 }  { Generator Loss --> 0.202291 }  { Discriminator Loss --> 0.849359 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 21 of 77 }  { Generator Loss --> 0.465055 }  { Discriminator Loss --> 0.528434 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 22 of 77 }  { Generator Loss --> 0.598769 }  { Discriminator Loss --> 0.460923 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 23 of 77 }  { Generator Loss --> 0.395063 }  { Discriminator Loss --> 0.560059 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 24 of 77 }  { Generator Loss --> 0.532995 }  { Discriminator Loss --> 0.442042 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 25 of 77 }  { Generator Loss --> 0.903821 }  { Discriminator Loss --> 0.401002 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 26 of 77 }  { Generator Loss --> 0.504403 }  { Discriminator Loss --> 0.463517 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 27 of 77 }  { Generator Loss --> 0.555878 }  { Discriminator Loss --> 0.426512 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 28 of 77 }  { Generator Loss --> 0.872366 }  { Discriminator Loss --> 0.270680 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 29 of 77 }  { Generator Loss --> 1.428611 }  { Discriminator Loss --> 0.352139 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 30 of 77 }  { Generator Loss --> 0.154782 }  { Discriminator Loss --> 0.978521 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 31 of 77 }  { Generator Loss --> 0.111146 }  { Discriminator Loss --> 1.140314 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 32 of 77 }  { Generator Loss --> 0.249068 }  { Discriminator Loss --> 0.763507 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 33 of 77 }  { Generator Loss --> 0.683885 }  { Discriminator Loss --> 0.377880 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 34 of 77 }  { Generator Loss --> 1.084611 }  { Discriminator Loss --> 1.694348 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 35 of 77 }  { Generator Loss --> 0.008996 }  { Discriminator Loss --> 2.405951 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 36 of 77 }  { Generator Loss --> 0.025108 }  { Discriminator Loss --> 1.856982 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 37 of 77 }  { Generator Loss --> 0.547457 }  { Discriminator Loss --> 0.432310 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 38 of 77 }  { Generator Loss --> 4.593207 }  { Discriminator Loss --> 12.874922 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 39 of 77 }  { Generator Loss --> 0.097992 }  { Discriminator Loss --> 1.196068 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 40 of 77 }  { Generator Loss --> 0.102787 }  { Discriminator Loss --> 1.169901 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 41 of 77 }  { Generator Loss --> 0.217525 }  { Discriminator Loss --> 0.818585 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 42 of 77 }  { Generator Loss --> 0.394886 }  { Discriminator Loss --> 0.560914 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 43 of 77 }  { Generator Loss --> 0.686096 }  { Discriminator Loss --> 0.462434 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 44 of 77 }  { Generator Loss --> 0.253561 }  { Discriminator Loss --> 0.749903 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 45 of 77 }  { Generator Loss --> 0.280811 }  { Discriminator Loss --> 0.705985 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 46 of 77 }  { Generator Loss --> 0.532052 }  { Discriminator Loss --> 0.442974 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 47 of 77 }  { Generator Loss --> 1.074638 }  { Discriminator Loss --> 0.258895 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 48 of 77 }  { Generator Loss --> 1.467979 }  { Discriminator Loss --> 1.246155 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 49 of 77 }  { Generator Loss --> 0.069036 }  { Discriminator Loss --> 1.372701 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 50 of 77 }  { Generator Loss --> 0.056860 }  { Discriminator Loss --> 1.465938 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 51 of 77 }  { Generator Loss --> 0.119488 }  { Discriminator Loss --> 1.097556 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 52 of 77 }  { Generator Loss --> 0.246211 }  { Discriminator Loss --> 0.762394 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 53 of 77 }  { Generator Loss --> 0.471422 }  { Discriminator Loss --> 0.489574 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 54 of 77 }  { Generator Loss --> 1.052540 }  { Discriminator Loss --> 0.221421 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 55 of 77 }  { Generator Loss --> 1.767148 }  { Discriminator Loss --> 0.512516 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 56 of 77 }  { Generator Loss --> 0.371174 }  { Discriminator Loss --> 0.585829 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 57 of 77 }  { Generator Loss --> 0.326675 }  { Discriminator Loss --> 0.639478 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 58 of 77 }  { Generator Loss --> 0.453747 }  { Discriminator Loss --> 0.504355 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 59 of 77 }  { Generator Loss --> 0.671733 }  { Discriminator Loss --> 0.357711 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 60 of 77 }  { Generator Loss --> 1.002706 }  { Discriminator Loss --> 0.233477 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 61 of 77 }  { Generator Loss --> 1.315783 }  { Discriminator Loss --> 0.738501 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 62 of 77 }  { Generator Loss --> 0.229173 }  { Discriminator Loss --> 0.794211 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 63 of 77 }  { Generator Loss --> 0.196122 }  { Discriminator Loss --> 0.865806 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 64 of 77 }  { Generator Loss --> 0.335180 }  { Discriminator Loss --> 0.629018 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 65 of 77 }  { Generator Loss --> 0.579665 }  { Discriminator Loss --> 0.410915 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 66 of 77 }  { Generator Loss --> 0.927608 }  { Discriminator Loss --> 0.297133 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 67 of 77 }  { Generator Loss --> 1.113816 }  { Discriminator Loss --> 0.388010 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 68 of 77 }  { Generator Loss --> 0.548608 }  { Discriminator Loss --> 0.432435 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 69 of 77 }  { Generator Loss --> 1.822359 }  { Discriminator Loss --> 0.090340 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 70 of 77 }  { Generator Loss --> 3.080707 }  { Discriminator Loss --> 0.034378 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 71 of 77 }  { Generator Loss --> 2.099912 }  { Discriminator Loss --> 0.536095 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 72 of 77 }  { Generator Loss --> 0.216947 }  { Discriminator Loss --> 0.874488 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 73 of 77 }  { Generator Loss --> 0.253218 }  { Discriminator Loss --> 0.750842 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 74 of 77 }  { Generator Loss --> 0.687346 }  { Discriminator Loss --> 0.349747 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 75 of 77 }  { Generator Loss --> 1.377320 }  { Discriminator Loss --> 0.289000 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 76 of 77 }  { Generator Loss --> 1.281163 }  { Discriminator Loss --> 0.381520 }\n",
            "{ Epoch --> 1 of 1}  { Batch --> 77 of 77 }  { Generator Loss --> 0.300728 }  { Discriminator Loss --> 0.676541 }\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3sl7X8oCCqYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}